<1과목>
1. 빅데이터
    1) 데이터 
        - 가역(이력추적가능)/불가역(원본환원불가)
        - 노나카 지식창조매커니즘 (공표연내) : 공통화(공유)/표출화(형식지)/연결화(체계화)/내면화(개인)
        - 지식의 피라미드(DIKW) : 데이터(100원)/정보(더 저렴)/지식(사야겠다)/지혜(다른것도)
        - 정보의특징 : 3정1관(정확성, 적절성, 적시성, 관련성)
    2) 빅데이터
        - 3V(용량,다양,속도)+2V(품질,가치)
        - 활용 3요소 : 자원, 기술, 인력(분석+IT+비즈니스)
        - 조직 : 집중형(별도전담조직,우선순위,이원화)/분산형(현업에 빠르게 적용)
          - 준비-성숙 4분면(정확준도) : 정착, 확산, 준비, 도입
        - 진화 : 처리 - 통합- 분석 - 연결 - 권리(마이데이터) 
        - 새로운 아이디어 제공 : 서비스 아닌 현업에서 도출
    3) 제도
        - 데이터3법 : 개인정보보호법+망+신용 / 개인정보 판단기준 명확화 / (가명정보/익명화)
        - 비식별화 : 사전-비식별(가명/범주/삭제/총계/마스킹)-적정성(k익명성/t근접성/l다양성)-사후

2. 빅데이터 분석 기획
    1) 과제발굴 방법론
        - 대상-방식 4분면 : Optimization(둘다앎),I(대상모름,방법앎),S,Discovery(둘다모름)
        - 과제 우선순위(시급성-난이도) 4분면 : 1,2,3,4(3 > 시급성4, 난이도1 > 2)
        - 하향식 : 문제->방안 / 탐색 - 정의 - 방안 - 평가
        - 상향식 : 데이터->문제 / 
        - 혼합식 : 수렴과 발산 반복 
        - ROI 투자비용 요소 : 크기, 형태, 속도 <-> 비즈니스 효과 : 가치
        - 목표시점 분류 : 단기(Quick-Win) / 중장기(문화내제화) / 혼합(빠르게 가치 조기 체험)

    2) 분석 방법론
        1) 계층적 프로세스(PTS) : 단계-태스크-스텝
        2) SW개발생명주기 
            - 폭포수 : 순차
            - 프로토타입 : MVP
            - 나선형 : 점진적(관리복잡)
            - 반복형 : 증분형(증분마다 설계,구현,운영 병행) / 진화형(완료 후 증분 개발, 릴리즈)
        3) KDD(Fayyad) : 선택(Selection) - 전처리 - 변환 - 마이닝 - 평가
        4) CRISP-DM : 업무이해-데이터이해-데이터준비-모델링-평가-전개(Deployee)
        5) SEMMA(SAS) : 추출(Sample)-탐색-수정-모델링-평가
        6) 빅데이터 분석방법론 5단계 : 기획(Planning)-준비-분석(데이터준비)-구현-평가 및 전개(모델발전계획)

    3) 계획
        - 데이터 처리 프로세스 : 소스-수집-저장-처리- // -분석-표현
        - 작업분할구조(WBS) 수립 절차 : 비용 배분, 구조 수립, 업무 분장
        - 작업분할구조도 절차 : 과제 정의 - 준비와 탐색 - 모델링 및 검증 - *산출물 정리
        - 분석목표정의서 구성요소 : 원천데이터 조사, 방안 및 적용가능성, 평가

3. 빅데이터 기술(수집,저장,처리)
    1) 수집 
        - 수집시스템 구축 절차 : *유형파악 - *기술결정 - 아키텍처 - HW - 실행환경
        - 정형 품질기준(유유정일완) : 완전, 유일, 유효, 일관, 정확
        - 비정형 품질기준(이신사효기) : 기능, 신뢰, 사용, 효율, 이식

    2) 저장
        - 기능성(확장성, 일관성, 질의지원, 접근성) <-> *연계성(호환성)
        - NoSQL 분류
            - Key-Value : Redis(RDBMS보다 확장성 뛰어남)
            - 컬럼지향 : Cassnadra, HBase
            - 문서 : Mongo, Couch(Restful API, 웹강점)
    
    3) 처리
        - ETL - ODS(다양한 추출) - CDC(실시간ETL) 
        - OLTP(DB,트랜잭션,정규)/OLAP(DW,분석,비정규)
        - DW : 모델, ETL(추출+변환+적재/수집기술), ODS, OLAP
        - 데이터레이크 : 하둡
        - 맵리듀스 : 입력-분할-MAP-SHUFFLE-파티션-REDUCE

<2과목>
1. 전처리
    - 명(성별)서(설문점수)등(온도)비(키) 
    - 횡적자료(시간x) / 종적자료(시계열+횡적)
    1) 정제
        1) 결측값
            - MCAR(완전무작위) : 다른 변수와 무관(ex.데이터누락)
            - MAR(무작위) : 다른 변수 연관 + 비관측값 무관(ex.여성 체중 미응답)
            - NMAR(비무작위) : 결측이유(종속변수)와 연관(ex.뚱뚱한 사람 미응답)
            - 단순대치법 : 삭제 / 평균(표준오차 과소추정됨) / 회귀(조건부 평균 대치) / 
              단순확률(확률추출 무작위 대치) / 최근방(결측값 바로 이전값)
            - 다중대치법 : 대치 - 분석 - 결합
        2) 이상값
            - 원인 : 입력실수 / 측정오류 / 실험오류 / 의도적(남성 키) / 처리오류(전처리) / 표본오류(샘플링 편향)
            - 탐지 :
                1) 시각화(비모수,단변량) : box-plot, 줄기-잎 그림, 산점도
                2) Z-Score(모수,저변량) : 정규화(68%,95%,99%)
                3) DBSCAN(밀도기반 클러스터링) : 군집에서 먼 거리
                4) 고립 의사나무 : node 길이로 판단

    2) 변수처리(피처엔지니어링)
        1) 변수선택 
            - 전진선택법 : 영모형 + F검정 통계량(종속변수와의 상관계수)이 가장 큰 변수부터 추가
            - 후진선택법 : 전체모델 + 상관계수 가장 작은 변수 제거 + F 유의하지 않으면 제거
            - 단계적선택법 : 전진 + 후진
        2) 차원축소 
            - 필요성(해복과) : 해석력, 복잡도, 과적합
            1) 요인분석 : 기술통계. 
            2) 주성분분석 : 선형연관성이 없는 저차원 특징 추출. 직교변환. 분포특성 최대한 보존.
                변수 간 상관이 있을때만 가능. 스케일링 필수.
            3) SVD(특이값분해) : M=(직교행렬m*n)(대각행렬m*n)(직교행렬n*n)
                * 직교행렬 : 전치행렬=역행렬
                * 대각행렬 : 대각성분 제외 나머지 0
                * 몇개의 k(특이값)만으로도 유사 행렬을 만들 수 있다.
            4) NMF(행렬과 음수 미포함 행렬분해) : V=WH+U
                * 분해한 행렬 하나가 전체 대략 정보(해)를 제시한다.
        3) 파생변수
            1) 파생변수 : 대표성 띄어야 함. 총합, 평균, 표준점수, 영역별 난이도 등
            2) 요약변수 : 집계(aggregate), DM 기본변수, 재활용성 높음, (ex. 개수, 횟수 등)
        4) 변수변환
            1) 범주형변환 : 연속형을 범주형으로 나누어 비교하면 설명이 효과적임.(상위10%)
            2) 정규화 : 만점 대비 / 최대최소([(X-min)/(max-min)]) / Z-점수([(X-평균)/분산])
               * 지수(좌측) - 제곱근(약간우측) - 로그(우측) - 역수(극단우측) : 선형, 정규분포 특성으로 변환 가능
               * 정규성검정 : 샤피로테스트, Q-Q Plot 
        5) 불균형 처리
            - 정확도가 높아도 재현율(TP/TP+FN)이 급격히 떨어짐
            1) 가중치 균형 : 고정비율(클래스 역비율을 가중치로), 최적비율(가중치 찾는 과정)
            2) 샘플링 : 언더샘플링(큰쪽을 일부만 선택), 오버샘플링(작은쪽을 큰쪽만큼 만듦)

2. EDA
    1) 상관분석 : 단순/다중/편
        1) 기본가정 : 독(독립표본,확률선정),선(선형성,산점도),등(Y퍼진정도일정),정(모집단 정규분포)
        2) 피어슨 상관계수 = (공분산)/(x표준편차 * y표준편차) = - +1 ~ -1 
            - 공분산 = 분(합(X편차*Y편차))
        3) 스피어만 상관계수 = 1 - ((6*합(x순위-y순위)^2)/(n*(n^2-1)))
            - 서열자료만 가능. 이상치 및 표본 작을 때 유용.
            
    2) 기초통계량
        1) 중심화 경향 : 산술(분합(x)) >= 기하(n루트(곱(x))=평균률), 중앙값(서수(n+1)/2), 최빈값, 분위수
        2) 산포도 : 분산(분합(편차제곱), 특이점에 취약), 범위(최대-최소), 평균절대편차(MAD, 분합절대, 특이점 영향적음), 사분위편차(Q3-Q1), 변동계수(CV=표준편차/평균*100)
        3) 분포형태 : 왜도(치우침정도, 3제곱), 첨도(뾰족정도, 4제곱, 3이면 정규분포)
        
    3) 시각적탐색